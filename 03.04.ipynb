{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ff5e43-093f-44d1-a06a-88a0a858c6f5",
   "metadata": {},
   "source": [
    "# Q1. Explain the concept of precision and recall in the context of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58d5b0-1cdb-468a-8af6-88f039078563",
   "metadata": {},
   "source": [
    "In the context of classification models, precision and recall are two important performance metrics that are used to evaluate the model's ability to make correct predictions for the positive class (usually the minority or target class). Both precision and recall are calculated based on the contents of a confusion matrix.\n",
    "\n",
    "Precision: Precision measures the accuracy of positive predictions made by the model. It is the ratio of true positive predictions to the total number of positive predictions made by the model. In other words, precision tells us how many of the predicted positive instances are actually correct.\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate): Recall measures the ability of the model to identify all positive instances in the dataset. It is the ratio of true positive predictions to the total number of actual positive instances. In other words, recall tells us how many of the actual positive instances were correctly predicted by the model.\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "True Positives (TP): The number of instances that are correctly predicted as positive by the model.\n",
    "\n",
    "False Positives (FP): The number of instances that are incorrectly predicted as positive by the model (they are actually negative).\n",
    "\n",
    "False Negatives (FN): The number of instances that are incorrectly predicted as negative by the model (they are actually positive).\n",
    "\n",
    "A high precision indicates that the model has a low rate of false positives, meaning that when it predicts a positive instance, it is likely to be correct. On the other hand, a high recall indicates that the model has a low rate of false negatives, meaning that it can identify a large proportion of actual positive instances.\n",
    "\n",
    "In some situations, precision and recall may be in conflict with each other. For example, increasing the threshold for positive predictions may improve precision but reduce recall, and vice versa. The trade-off between precision and recall depends on the specific use case and the consequences of false positives and false negatives.\n",
    "\n",
    "In summary, precision and recall provide valuable insights into the performance of a classification model, especially in imbalanced datasets, where one class is significantly larger than the other. They help assess the model's accuracy and its ability to correctly identify positive instances, which is crucial in various real-world applications like fraud detection, disease diagnosis, and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b6fcc-94c1-44b1-9539-4545b23c9572",
   "metadata": {},
   "source": [
    "# Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a560b4-b7dd-46f8-91a3-8c5ab2d3db8e",
   "metadata": {},
   "source": [
    "The F1 score is a single performance metric that combines both precision and recall into one score, providing a balanced evaluation of a classification model. It is particularly useful when dealing with imbalanced datasets, where one class is much larger than the other.\n",
    "\n",
    "The F1 score is calculated using the harmonic mean of precision and recall:\n",
    "\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Precision and recall are defined as follows \n",
    "\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "The F1 score ranges between 0 and 1, where a perfect classifier has an F1 score of 1, and a completely ineffective classifier has an F1 score of 0.\n",
    "\n",
    "The main difference between the F1 score, precision, and recall lies in their focus on different aspects of the model's performance:\n",
    "\n",
    "Precision: Focuses on the accuracy of positive predictions. It answers the question: \"Of all the instances predicted as positive, how many were actually positive?\" High precision means the model has a low rate of false positives.\n",
    "\n",
    "Recall: Focuses on the ability of the model to identify all positive instances. It answers the question: \"Of all the actual positive instances, how many did the model correctly identify as positive?\" High recall means the model has a low rate of false negatives.\n",
    "\n",
    "F1 Score: Combines precision and recall into a single metric. It takes both false positives and false negatives into account, making it useful when both precision and recall are important. The F1 score is the harmonic mean of precision and recall, and it balances the trade-off between the two metrics.\n",
    "\n",
    "In imbalanced datasets, where one class is much larger than the other, accuracy alone may not provide a complete picture of the model's performance. A model can achieve high accuracy by simply predicting the majority class all the time, but it may perform poorly in terms of correctly identifying instances of the minority class. The F1 score considers both precision and recall, making it a more reliable evaluation metric for imbalanced datasets and scenarios where both false positives and false negatives matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de58c5-0c81-4553-86e7-3151954b36d6",
   "metadata": {},
   "source": [
    "# Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3e821-2bf5-436f-8285-a41ecd1eeaca",
   "metadata": {},
   "source": [
    "ROC (Receiver Operating Characteristic) and AUC (Area Under the Curve) are evaluation metrics used to assess the performance of classification models, particularly binary classifiers. They help visualize and quantify the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) at different classification thresholds.\n",
    "\n",
    "Here's an explanation of both terms:\n",
    "\n",
    "ROC (Receiver Operating Characteristic): The ROC curve is a graphical representation of the true positive rate (TPR) against the false positive rate (FPR) for different threshold values of a binary classifier. The TPR (also known as sensitivity or recall) represents the percentage of true positive predictions (correctly predicted positive instances) out of all actual positive instances. The FPR, on the other hand, represents the percentage of false positive predictions (incorrectly predicted positive instances) out of all actual negative instances.\n",
    "The ROC curve is plotted by calculating TPR and FPR at different probability thresholds. Each point on the curve represents a specific threshold value. The ideal ROC curve hugs the top-left corner of the graph, indicating high TPR and low FPR. A random classifier would have an ROC curve that is a diagonal line from the bottom-left to the top-right of the graph.\n",
    "\n",
    "AUC (Area Under the Curve): The AUC is a single scalar value that quantifies the overall performance of a classifier represented by the ROC curve. It measures the area under the ROC curve, which ranges from 0 to 1. The AUC value provides a simple way to compare the performance of different classifiers. A perfect classifier has an AUC of 1, while a completely ineffective classifier (e.g., random guessing) has an AUC of 0.5.\n",
    "In summary, the ROC curve helps visualize how a binary classifier's sensitivity and specificity change as the classification threshold varies, while the AUC provides a single numerical value that summarizes the classifier's performance. A higher AUC generally indicates better model performance, with values closer to 1 indicating better discriminative ability between the positive and negative classes. Both ROC and AUC are particularly useful when evaluating models in imbalanced datasets, where class distribution is skewed, and accuracy alone may not be an adequate evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a385ef-f59d-493b-8eb3-e0238e044b8a",
   "metadata": {},
   "source": [
    "# Q4. How do you choose the best metric to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64215f34-6339-4ba6-8650-e147da7ca780",
   "metadata": {},
   "source": [
    "Choosing the best metric to evaluate the performance of a classification model depends on the specific problem and the priorities of the task at hand. Different evaluation metrics emphasize different aspects of the model's performance, and the choice of the metric should align with the project's objectives and requirements. Here are some common scenarios and the corresponding metrics to consider:\n",
    "\n",
    "Accuracy: Accuracy is a straightforward metric that measures the overall correctness of the model's predictions. It is suitable when the classes are balanced, and there is no significant class imbalance. However, accuracy may not be the best choice when dealing with imbalanced datasets, as it can be misleading when one class dominates the others.\n",
    "\n",
    "Precision: Precision measures the proportion of true positive predictions (correctly predicted positive instances) out of all positive predictions made by the model. It is useful when the cost of false positives is high and you want to minimize the number of false positives.\n",
    "\n",
    "Recall (Sensitivity): Recall measures the proportion of true positive predictions out of all actual positive instances. It is useful when the cost of false negatives is high, and you want to minimize the number of false negatives.\n",
    "\n",
    "F1 Score: The F1 score is the harmonic mean of precision and recall. It is useful when you want to balance both precision and recall, especially in situations where there is an uneven class distribution.\n",
    "\n",
    "ROC AUC: ROC AUC is suitable when you want to evaluate the model's performance across different classification thresholds and the classes are imbalanced. It provides an overall measure of the model's ability to distinguish between the positive and negative classes.\n",
    "\n",
    "Specificity: Specificity measures the proportion of true negative predictions (correctly predicted negative instances) out of all actual negative instances. It is useful when the cost of false negatives is high, and you want to minimize the number of false negatives.\n",
    "\n",
    "The choice of the best metric also depends on the specific application and the context of the problem. It is essential to consider the business requirements, the impact of different types of errors, and the distribution of the classes in the dataset. In some cases, multiple metrics may be used together to provide a comprehensive evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbbc80-713d-46d0-b953-698e71b75019",
   "metadata": {},
   "source": [
    "# Q5. What is multiclass classification and how is it different from binary classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7b15a-a4f7-4a4a-b939-e4b0a58cad67",
   "metadata": {},
   "source": [
    "Multiclass classification is a type of classification problem in machine learning where the goal is to assign an input instance to one of three or more classes. Each class is distinct and mutually exclusive, meaning that an instance can belong to only one class. The model's objective is to learn the mapping between input features and multiple output classes.\n",
    "\n",
    "On the other hand, binary classification is a type of classification problem where the goal is to assign an input instance to one of two classes. The classes are often referred to as the positive class (class 1) and the negative class (class 0). Unlike multiclass classification, binary classification deals with only two possible outcomes.\n",
    "\n",
    "The key differences between multiclass and binary classification are as follows:\n",
    "\n",
    "Number of Classes:\n",
    "\n",
    "Multiclass classification deals with three or more classes, and each instance is assigned to one of these multiple classes.\n",
    "Binary classification deals with only two classes, and each instance is assigned to either the positive or negative class.\n",
    "\n",
    "\n",
    "Decision Boundaries:\n",
    "\n",
    "In multiclass classification, the model must learn multiple decision boundaries to separate each class from the others.\n",
    "In binary classification, there is only one decision boundary that separates the positive class from the negative class.\n",
    "\n",
    "\n",
    "Evaluation Metrics:\n",
    "\n",
    "In multiclass classification, evaluation metrics such as accuracy, precision, recall, F1 score, and multiclass log-loss are used to measure the model's performance across all classes.\n",
    "In binary classification, evaluation metrics such as accuracy, precision, recall, F1 score, ROC AUC, and log-loss are commonly used to measure the model's performance.\n",
    "\n",
    "\n",
    "One-vs-Rest (OvR) or One-vs-One (OvO) Approach:\n",
    "\n",
    "In multiclass classification, two common approaches are used to handle the multiple classes: One-vs-Rest (OvR) and One-vs-One (OvO).\n",
    "In binary classification, there is no need for these approaches since there are only two classes.\n",
    "In summary, the main difference between multiclass and binary classification lies in the number of classes involved and how the model handles the decision boundaries and evaluation metrics. Multiclass classification is more complex and requires additional techniques to handle multiple classes effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf665204-1257-44b7-9373-29a5e5d6bc8f",
   "metadata": {},
   "source": [
    "# Q6. Explain how logistic regression can be used for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52dde56-d1d0-40d5-8126-ff0472fb31c1",
   "metadata": {},
   "source": [
    "Logistic regression is originally designed for binary classification problems, where the goal is to predict one of two possible outcomes (e.g., yes/no, true/false, positive/negative). However, it can also be extended to handle multiclass classification problems using various techniques. Two common approaches for using logistic regression for multiclass classification are the One-vs-Rest (OvR) and the One-vs-One (OvO) strategies.\n",
    "\n",
    "One-vs-Rest (OvR) Approach:\n",
    "In the OvR approach, also known as the one-vs-all approach, we create a separate binary logistic regression model for each class in the multiclass problem. For example, if we have three classes (A, B, and C), we create three binary classifiers: one for class A (versus non-A), one for class B (versus non-B), and one for class C (versus non-C).\n",
    "During the training phase, each binary classifier is trained to distinguish its target class from all other classes combined. When making predictions for a new instance, we pass it through all the binary classifiers, and the class associated with the classifier with the highest predicted probability is assigned as the final class label.\n",
    "\n",
    "One-vs-One (OvO) Approach:\n",
    "In the OvO approach, we create a binary classifier for every pair of classes in the multiclass problem. For example, if we have three classes (A, B, and C), we create three binary classifiers: one for class A versus class B, one for class A versus class C, and one for class B versus class C.\n",
    "During training, each binary classifier is trained on the subset of data containing only the two classes it is designed to distinguish. When making predictions, we again pass the instance through all binary classifiers, and each classifier \"votes\" for its predicted class. The final class label is determined by the class that receives the most votes.\n",
    "\n",
    "Both OvR and OvO strategies allow us to use logistic regression for multiclass classification tasks. OvR is more computationally efficient and is the more commonly used approach for logistic regression with multiple classes. However, OvO may be preferred in cases where binary classifiers work well on smaller subsets of data and where computational resources are not a significant constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766480aa-b215-4ab7-91c9-ca3f138a82dc",
   "metadata": {},
   "source": [
    "# Q7. Describe the steps involved in an end-to-end project for multiclass classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9b3d5-cc6c-4a39-ad12-f3c10a931397",
   "metadata": {},
   "source": [
    "An end-to-end project for multiclass classification typically involves the following steps:\n",
    "\n",
    "Data Collection: Gather the dataset that contains features (independent variables) and corresponding class labels (target variable) for each instance. Ensure that the dataset is representative and well-prepared for analysis.\n",
    "\n",
    "Data Preprocessing: Clean the data by handling missing values, outliers, and duplicates. Perform feature scaling or normalization if required. Split the dataset into training and testing sets.\n",
    "\n",
    "Model Selection: Choose a suitable classification algorithm for multiclass classification, such as logistic regression, decision trees, random forests, support vector machines, or neural networks, based on the nature of the data and the problem.\n",
    "\n",
    "Model Training: Fit the selected classification model on the training data. Use techniques like One-vs-Rest or One-vs-One for logistic regression if it's the chosen algorithm.\n",
    "\n",
    "Model Evaluation: Assess the performance of the model using evaluation metrics like accuracy, precision, recall, F1-score, and confusion matrix on the testing data. Fine-tune the model parameters if necessary.\n",
    "\n",
    "Hyperparameter Tuning: Use techniques like Grid Search or Randomized Search to find the optimal hyperparameters for the chosen model.\n",
    "\n",
    "Model Deployment: Once the model is trained and evaluated, deploy it to make predictions on new and unseen data. This could involve integrating the model into a web application or API.\n",
    "\n",
    "Performance Monitoring: Continuously monitor the performance of the deployed model and update it as needed to maintain accuracy.\n",
    "\n",
    "Documentation: Thoroughly document all the steps, methodologies, and findings of the project. This documentation is essential for reproducibility and future reference.\n",
    "\n",
    "Communication: Prepare a report or presentation to communicate the results and insights gained from the multiclass classification project to stakeholders or team members.\n",
    "\n",
    "Throughout the entire project, ensure data privacy and security and adhere to best practices in machine learning to produce accurate and reliable predictions for the multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434db9fc-9fac-4075-aca5-892eee29ba9a",
   "metadata": {},
   "source": [
    "# Q8. What is model deployment and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e733c7d-9dc9-4dde-913b-267754b7672b",
   "metadata": {},
   "source": [
    "Model deployment is the process of integrating a trained machine learning model into a production environment, where it can be used to make real-time predictions on new data. In simpler terms, it means putting the model to work in a practical setting, making it accessible for end-users or applications to utilize its predictions.\n",
    "\n",
    "The importance of model deployment lies in the following aspects:\n",
    "\n",
    "Real-world Applications: Deploying a model allows organizations to leverage the insights gained from data analysis and machine learning to make informed decisions in real-world scenarios. This can lead to improved efficiency, cost savings, and enhanced user experiences.\n",
    "\n",
    "Automation: Deployed models can automate various tasks, such as fraud detection, recommendation systems, or predictive maintenance, reducing the need for manual intervention and increasing overall efficiency.\n",
    "\n",
    "Faster Decision-Making: By deploying models, organizations can make rapid and data-driven decisions in real-time, enabling them to respond quickly to changes in the environment.\n",
    "\n",
    "Scalability: Deploying models in a production environment ensures that they can handle large volumes of data and user requests efficiently, making them suitable for enterprise-level applications.\n",
    "\n",
    "Continuous Learning and Improvement: Deployed models can be monitored for their performance, and any issues or inaccuracies can be addressed promptly. This feedback loop enables continuous learning and improvement of the model over time.\n",
    "\n",
    "Return on Investment (ROI): Model deployment allows organizations to realize the return on investment made in developing and training the machine learning model. The model's successful deployment can lead to tangible benefits and improved business outcomes.\n",
    "\n",
    "Easy Integration: A properly deployed model provides APIs or interfaces that make it easy for developers to integrate the model's predictions into existing software or applications.\n",
    "\n",
    "Overall, model deployment is a crucial step in the machine learning lifecycle, as it bridges the gap between research and practical application, enabling businesses to leverage the power of data science to enhance their operations and decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce29e40-6386-4c64-89a7-32999cf51815",
   "metadata": {},
   "source": [
    "# Q9. Explain how multi-cloud platforms are used for model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985493c-f117-461c-acdd-8b63ed26c02c",
   "metadata": {},
   "source": [
    "Multi-cloud platforms refer to the practice of using more than one cloud provider to deploy and run applications and services. In the context of model deployment, multi-cloud platforms offer several benefits and strategies for organizations looking to leverage the advantages of multiple cloud providers. Here's how multi-cloud platforms are used for model deployment:\n",
    "\n",
    "Flexibility and Redundancy: By deploying models on multiple cloud platforms, organizations gain flexibility and redundancy. If one cloud provider experiences downtime or technical issues, the model can fail over to another provider, ensuring continuous availability and minimal disruptions.\n",
    "\n",
    "Cost Optimization: Different cloud providers may offer varying pricing models and discounts, allowing organizations to optimize costs by choosing the most cost-effective option for model deployment.\n",
    "\n",
    "Avoiding Vendor Lock-in: Multi-cloud deployments help prevent vendor lock-in, where an organization becomes heavily dependent on a single cloud provider's services. Using multiple providers allows for easier migration of models and applications if necessary.\n",
    "\n",
    "Regional Reach: Different cloud providers have data centers in various regions worldwide. Deploying models across multiple cloud platforms enables organizations to serve predictions and services from data centers closest to end-users, reducing latency and improving user experience.\n",
    "\n",
    "Performance and Scalability: Multi-cloud platforms allow organizations to leverage each provider's unique strengths in terms of performance and scalability. Models can be deployed on the cloud that offers the best performance for specific workloads.\n",
    "\n",
    "Compliance and Data Residency: Some organizations may have specific regulatory or compliance requirements that mandate the use of certain cloud providers. By deploying models on multiple clouds, organizations can ensure compliance with various data residency regulations.\n",
    "\n",
    "Disaster Recovery and Backup: Multi-cloud platforms facilitate disaster recovery and backup strategies. If one cloud provider experiences a significant outage or data loss, models and data can be recovered from another provider's backup.\n",
    "\n",
    "Experimentation and Innovation: Deploying models on multiple clouds enables organizations to experiment and innovate with new cloud services and features from different providers, driving technological advancements and best practices.\n",
    "\n",
    "It's important to note that managing and deploying models on multi-cloud platforms can be complex, as it requires dealing with different APIs, security considerations, and operational challenges. Organizations should carefully plan and architect their multi-cloud strategy to ensure smooth model deployment and optimal utilization of cloud resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ebc5d-c7c3-4c7a-b63e-f571946c479d",
   "metadata": {},
   "source": [
    "# Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdebaf-5ac5-4f7c-a4ad-a3bfdb984ba7",
   "metadata": {},
   "source": [
    "Deploying machine learning models in a multi-cloud environment offers several benefits and opportunities, but it also comes with its own set of challenges. Let's explore both aspects:\n",
    "\n",
    "Benefits of Deploying Machine Learning Models in a Multi-Cloud Environment:\n",
    "\n",
    "Redundancy and High Availability: Multi-cloud deployment ensures redundancy, making the models highly available. If one cloud provider experiences downtime, the models can continue serving predictions from other cloud platforms.\n",
    "\n",
    "Flexibility and Vendor Independence: Organizations can avoid vendor lock-in by distributing their models across multiple cloud providers. This provides the freedom to choose and switch between providers based on changing business requirements or service quality.\n",
    "\n",
    "Geographical Reach: Multi-cloud deployment allows organizations to deploy models in various regions, reaching users globally with low latency. This improves the overall performance and user experience.\n",
    "\n",
    "Cost Optimization: Different cloud providers offer varying pricing models and discounts. By distributing models across multiple clouds, organizations can optimize costs based on the workload and resource requirements.\n",
    "\n",
    "Compliance and Data Residency: Some organizations have strict data residency regulations. Multi-cloud deployment allows data to be stored and processed in compliance with regional data privacy laws.\n",
    "\n",
    "Challenges of Deploying Machine Learning Models in a Multi-Cloud Environment:\n",
    "\n",
    "Complexity and Integration: Managing models across multiple cloud platforms can be complex. It requires dealing with different APIs, security protocols, and monitoring tools. Integrating and ensuring seamless communication between clouds can be challenging.\n",
    "\n",
    "Data Synchronization and Consistency: Keeping data consistent and synchronized across multiple clouds can be a daunting task. Data replication and synchronization mechanisms must be implemented to avoid discrepancies.\n",
    "\n",
    "Security and Access Control: Maintaining robust security practices across different cloud environments requires careful planning and implementation. Access control policies and authentication mechanisms must be enforced consistently.\n",
    "\n",
    "Operational Overhead: Multi-cloud deployments may require additional operational efforts, such as maintaining different monitoring systems, logging mechanisms, and backup strategies for each cloud.\n",
    "\n",
    "Performance Variability: Each cloud provider may offer different hardware configurations and performance capabilities. Ensuring consistent performance and scalability across all clouds can be challenging.\n",
    "\n",
    "Vendor-specific Services: Organizations that heavily rely on specific cloud services may face challenges in replicating those services across other cloud platforms. Vendor-specific features may not have direct equivalents in other clouds.\n",
    "\n",
    "Service Level Agreement (SLA) Management: Managing SLAs and ensuring consistent service quality across multiple clouds demands careful monitoring and governance.\n",
    "\n",
    "In conclusion, deploying machine learning models in a multi-cloud environment can provide numerous benefits in terms of redundancy, flexibility, and global reach. However, organizations must carefully address challenges related to complexity, data consistency, security, and performance to ensure successful multi-cloud deployment. Proper planning, architectural design, and ongoing management are essential to make the most of the advantages while overcoming the challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4ee71-a4f9-4821-b75a-38ec5026b5c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
